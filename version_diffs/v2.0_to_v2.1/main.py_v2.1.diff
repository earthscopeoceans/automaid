diff --git a/scripts/main.py b/scripts/main.py
index e32c40c..3f24209 100644
--- a/scripts/main.py
+++ b/scripts/main.py
@@ -2,11 +2,10 @@
 # pymaid environment (Python v2.7)
 #
 # Original author: Sebastien Bonnieux
-# Current maintainer: Dr. Joel D. Simon (JDS)
+# Current maintainer: Joel D. Simon (JDS)
 # Contact: jdsimon@alumni.princeton.edu | joeldsimon@gmail.com
-# Last modified by JDS: 16-Oct-2020, Python 2.7.15, Darwin-18.7.0-x86_64-i386-64bit
+# Last modified by JDS: 02-Nov-2020, Python 2.7.15, Darwin-18.7.0-x86_64-i386-64bit
 
-import setup
 import os
 import argparse
 import shutil
@@ -16,30 +15,45 @@ import dives
 import events
 import vitals
 import kml
+import gps
+import setup
 import re
 import utils
-import pickle
+from pprint import pprint
 from pdb import set_trace as keyboard
 
+# Get current version number.
+version = setup.get_version()
+
+# Set depth of mixed layer (in meters) for drift interpolation
+mixed_layer_depth_m = 50
+
 # Set default paths
 automaid_path = os.environ["AUTOMAID"]
 def_mermaid_path = os.environ["MERMAID"]
 def_server_path = os.path.join(def_mermaid_path, "server")
-def_processed_path = os.path.join(def_mermaid_path, "processed")
+def_processed_path = os.path.join(def_mermaid_path, "test_processed")
 
 # Parse (optional) command line inputs to override default paths
 parser = argparse.ArgumentParser()
-parser.add_argument('--server', default=def_server_path,
-                    help="path to server directory (default: {:s})".format(def_server_path))
-parser.add_argument('--processed', default=def_processed_path,
-                    help="path to processed directory (default: {:s})".format(def_processed_path))
+# problem: metavar=''   prints: "-s , --server"
+# problem: metavar='\b' prints: "-s, --server", but misaligns the help statement...
+parser.add_argument('-s',
+                    '--server',
+                    default=def_server_path,
+                    dest='server',
+                    #metavar='\b',
+                    help="server directory (default: {:s})".format(def_server_path))
+parser.add_argument('-p',
+                    '--processed',
+                    default=def_processed_path,
+                    dest='processed',
+                    #metavar='',
+                    help="processed directory (default: {:s})".format(def_processed_path))
 args = parser.parse_args()
 server_path = os.path.abspath(args.server)
 processed_path = os.path.abspath(args.processed)
 
-# Get current version number.
-version = setup.get_version()
-
 # Set a time range of analysis for a specific float
 filterDate = {
     "452.112-N-01": (datetime.datetime(2018, 12, 27), datetime.datetime(2100, 1, 1)),
@@ -49,22 +63,22 @@ filterDate = {
     "452.112-N-05": (datetime.datetime(2019, 1, 3), datetime.datetime(2100, 1, 1)),
     "452.020-P-06": (datetime.datetime(2018, 6, 26), datetime.datetime(2100, 1, 1)),
     "452.020-P-07": (datetime.datetime(2018, 6, 27), datetime.datetime(2100, 1, 1)),
-    "452.020-P-08": (datetime.datetime(2018, 8, 5), datetime.datetime(2100, 1, 1)),
-    "452.020-P-09": (datetime.datetime(2018, 8, 6), datetime.datetime(2100, 1, 1)),
-    "452.020-P-10": (datetime.datetime(2018, 8, 7), datetime.datetime(2100, 1, 1)),
-    "452.020-P-11": (datetime.datetime(2018, 8, 9), datetime.datetime(2100, 1, 1)),
-    "452.020-P-12": (datetime.datetime(2018, 8, 10), datetime.datetime(2100, 1, 1)),
-    "452.020-P-13": (datetime.datetime(2018, 8, 31), datetime.datetime(2100, 1, 1)),
-    "452.020-P-16": (datetime.datetime(2018, 9, 3), datetime.datetime(2100, 1, 1)),
-    "452.020-P-17": (datetime.datetime(2018, 9, 4), datetime.datetime(2100, 1, 1)),
-    "452.020-P-18": (datetime.datetime(2018, 9, 5), datetime.datetime(2100, 1, 1)),
-    "452.020-P-19": (datetime.datetime(2018, 9, 6), datetime.datetime(2100, 1, 1)),
-    "452.020-P-20": (datetime.datetime(2018, 9, 8), datetime.datetime(2100, 1, 1)),
-    "452.020-P-21": (datetime.datetime(2018, 9, 9), datetime.datetime(2100, 1, 1)),
-    "452.020-P-22": (datetime.datetime(2018, 9, 10), datetime.datetime(2100, 1, 1)),
-    "452.020-P-23": (datetime.datetime(2018, 9, 12), datetime.datetime(2100, 1, 1)),
-    "452.020-P-24": (datetime.datetime(2018, 9, 13), datetime.datetime(2100, 1, 1)),
-    "452.020-P-25": (datetime.datetime(2018, 9, 14), datetime.datetime(2100, 1, 1)),
+    "452.020-P-08": (datetime.datetime(2018, 1, 1), datetime.datetime(2100, 1, 1)),
+    "452.020-P-09": (datetime.datetime(2018, 1, 1), datetime.datetime(2100, 1, 1)),
+    "452.020-P-10": (datetime.datetime(2018, 1, 1), datetime.datetime(2100, 1, 1)),
+    "452.020-P-11": (datetime.datetime(2018, 1, 1), datetime.datetime(2100, 1, 1)),
+    "452.020-P-12": (datetime.datetime(2018, 1, 1), datetime.datetime(2100, 1, 1)),
+    "452.020-P-13": (datetime.datetime(2018, 1, 1), datetime.datetime(2100, 1, 1)),
+    "452.020-P-16": (datetime.datetime(2018, 1, 1), datetime.datetime(2100, 1, 1)),
+    "452.020-P-17": (datetime.datetime(2018, 1, 1), datetime.datetime(2100, 1, 1)),
+    "452.020-P-18": (datetime.datetime(2018, 1, 1), datetime.datetime(2100, 1, 1)),
+    "452.020-P-19": (datetime.datetime(2018, 1, 1), datetime.datetime(2100, 1, 1)),
+    "452.020-P-20": (datetime.datetime(2018, 1, 1), datetime.datetime(2100, 1, 1)),
+    "452.020-P-21": (datetime.datetime(2018, 1, 1), datetime.datetime(2100, 1, 1)),
+    "452.020-P-22": (datetime.datetime(2018, 1, 1), datetime.datetime(2100, 1, 1)),
+    "452.020-P-23": (datetime.datetime(2018, 1, 1), datetime.datetime(2100, 1, 1)),
+    "452.020-P-24": (datetime.datetime(2018, 1, 1), datetime.datetime(2100, 1, 1)),
+    "452.020-P-25": (datetime.datetime(2018, 1, 1), datetime.datetime(2100, 1, 1)),
     "452.020-P-0050": (datetime.datetime(2019, 8, 11), datetime.datetime(2100, 1, 1)),
     "452.020-P-0051": (datetime.datetime(2019, 7, 1), datetime.datetime(2100, 1, 1)),
     "452.020-P-0052": (datetime.datetime(2019, 7, 1), datetime.datetime(2100, 1, 1)),
@@ -83,7 +97,7 @@ events_sac = True
 events_png = False
 
 # Dictionary to save data in a file
-datasave = dict()
+dives_dict = dict()
 
 def main():
     # Set working directory in "scripts"
@@ -97,6 +111,10 @@ def main():
     vitfile_path = os.path.join(server_path, "*.vit")
     mfloats = [p.split("/")[-1][:-4] for p in glob.glob(vitfile_path)]
 
+    # Initialize empty dict to hold the instance of every last complete dive for
+    # every MERMAID
+    lastdive = dict()
+
     # For each Mermaid float
     for mfloat in mfloats:
         mfloat_serial = mfloat[-4:]
@@ -116,7 +134,8 @@ def main():
         if not os.path.exists(mfloat_path):
             os.mkdir(mfloat_path)
 
-        # Remove existing files in the processed directory (if the script have been interrupted the time before)
+        # Remove existing files in the processed directory (the script may have been previously
+        # executed, copied the files, then failed)
         for f in glob.glob(mfloat_path + "*.*"):
             os.remove(f)
 
@@ -166,13 +185,13 @@ def main():
 
         # Compute clock drift correction for each event, and build list of GPS locations.
         for dive in mdives:
-            dive.correct_events_clock_drift()
+            dive.correct_events_clockdrift()
 
         # Compute location of mermaid float for each event (because the station is moving)
         # the algorithm use gps information in the next dive to estimate surface drift
         i = 0
         while i < len(mdives)-1:
-            mdives[i].compute_events_station_location(mdives[i+1])
+            mdives[i].compute_station_locations(mdives[i+1], mixed_layer_depth_m)
             i += 1
 
         # Generate plots, SAC, and miniSEED files
@@ -196,45 +215,22 @@ def main():
             vitals.plot_corrected_pressure_offset(mfloat_path, mdives, begin, end)
 
 
-        # Concatenate all GPS fixes from every .LOG and .MER for every dive
-        gps_list_full = [g for d in mdives for g in d.gps_list]
-        gps_list_full.sort(key=lambda x: x.date)
-
-        # Write GPS text file
-        fmt_spec = "{:>27s}    {:>10.6f}    {:>11.6f}    {:>6.3f}    {:>6.3f}    {:>17.6f}    {:>15s}\n"
-        gps_f = os.path.join(processed_path, mfloat_path, mfloat+"_GPS.txt")
-        with open(gps_f, "w+") as f:
-            f.write("MERMAID: {:s}\n".format(mfloat))
-            f.write("COLUMN:                   1             2              3         4         5                    6                  7\n".format())
-            f.write("DESCRIPTION:       GPS_TIME       GPS_LAT        GPS_LON  GPS_HDOP  GPS_VDOP    GPS_TIME-MER_TIME             SOURCE\n".format())
-            for g in gps_list_full:
-                # Replace missing hdop/vdop (not printed in .MER files) values
-                # with NaNs for printing purposes (those attributes will remain
-                # None in their associated GPS instances; this is just for the
-                # purposes of this final flat list)
-                if g.hdop is None:
-                    g.hdop = float("NaN")
-                if g.vdop is None:
-                    g.vdop = float("NaN")
-
-                f.write(fmt_spec.format(g.date, g.latitude, g.longitude, g.hdop, g.vdop, g.clockdrift, g.source))
-
-        # Generate printout detailing how everything connects
-        print ""
-        i = 0
-        for d in mdives:
-            # For every dive...
-            if d.is_dive:
-                print("  .DIVE. {:s}".format(mfloat_serial))
-            else:
-                print("  .NO DIVE. {:s}".format(mfloat_serial))
-            d.print_dive_length()
-            d.print_dive_gps(mdives[i+1])
-            d.print_dive_events()
-            print ""
-
-        print("    {:s} total: {:d} SAC & miniSEED files\n" \
-              .format(mfloat_serial, sum(e.can_generate_sac for d in mdives for e in d.events)))
+        # Write text file containing all GPS fixes from .LOG and .MER
+        gps.write_gps_txt(mdives, processed_path, mfloat_path, mfloat)
+
+        # Write text file detailing event-station location interpolation parameters
+        gps.write_gps_interpolation_txt(mdives, processed_path, mfloat_path, mfloat)
+
+        # Write helpful printout detailing every dive, and how .LOG and .MER
+        # files connect
+        dives.generate_printout(mdives, mfloat_serial)
+
+        # Write the same info just printout do stdout to text file
+        dives.write_dives_txt(mdives, processed_path, mfloat_path, mfloat)
+
+        # Write a text file relating all SAC and mSEED to their associated .LOG
+        # and .MER files
+        events.write_traces_txt(mdives, processed_path, mfloat_path, mfloat)
 
         # Clean directories
         for f in glob.glob(mfloat_path + "/" + mfloat_nb + "_*.LOG"):
@@ -242,21 +238,17 @@ def main():
         for f in glob.glob(mfloat_path + "/" + mfloat_nb + "_*.MER"):
             os.remove(f)
 
-        # Put dive in a variable that will be saved in a file
-        datasave[mfloat] = mdives
-
-    with open(os.path.join(processed_path, "MerDives.pydata"), 'wb') as f:
-        pickle.dump(datasave, f)
-
-        # for dive in mdives[:-1]: # on ne regarde pas la derniere plongee qui n'a pas ete interpolee
-        #    if dive.is_complete_dive: # on ne regarde que les vraies plongees (pas les tests faits a terre)
-        #        print dive.log_name
-        #        for gps in dive.gps_list[0:-1]: # point GPS avant de descendre
-        #            print gps.date
-        #        print dive.surface_leave_loc.date
-        #        print dive.great_depth_reach_loc.date
-        #        print dive.great_depth_leave_loc.date
-        #        print dive.gps_list[-1].date # point GPS en arrivant en surface
+        # Add dives to growing dict
+        dives_dict[mfloat] = mdives
+
+
+    # Done looping through all dives for each float
+    #______________________________________________________________________________________#
+
+    # Print a text file of corrected external pressures measured on the final
+    # dive, and warn if any are approaching the limit of 300 mbar (at which
+    # point adjustment is required)
+    vitals.write_corrected_pressure_offset(dives_dict, processed_path)
 
 if __name__ == "__main__":
     main()
