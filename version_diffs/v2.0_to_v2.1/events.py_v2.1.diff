diff --git a/scripts/events.py b/scripts/events.py
index 56bff7e..f955d5f 100644
--- a/scripts/events.py
+++ b/scripts/events.py
@@ -2,11 +2,10 @@
 # pymaid environment (Python v2.7)
 #
 # Original author: Sebastien Bonnieux
-# Current maintainer: Dr. Joel D. Simon (JDS)
+# Current maintainer: Joel D. Simon (JDS)
 # Contact: jdsimon@alumni.princeton.edu | joeldsimon@gmail.com
-# Last modified by JDS: 16-Oct-2020, Python 2.7.15, Darwin-18.7.0-x86_64-i386-64bit
+# Last modified by JDS: 28-Oct-2020, Python 2.7.15, Darwin-18.7.0-x86_64-i386-64bit
 
-import setup
 import os
 import glob
 import re
@@ -22,36 +21,50 @@ import matplotlib.pyplot as plt
 import utils
 import gps
 import sys
+import setup
 from pdb import set_trace as keyboard
 
 # Get current version number.
 version = setup.get_version()
 
 class Events:
-    events = None
+    '''The Events (plural) class references a SINGLE .MER file, and all events that
+     live within it, which may be associated with the environments of multiple
+     other .MER files
 
-    def __init__(self, base_path=None, mmd_name=None):
-        # Initialize event list (if list is declared above, then elements of the
-        # previous instance are kept in memory)
-        self.__version__ = version
+     Multiple events (event binary blocks) may exist in a single Events.mer_name
+
+    '''
+
+    def __init__(self, base_path=None, mer_name=None):
+        self.mer_name = mer_name
+        self.base_path = base_path
         self.events = list()
+        self.__version__ = version
 
         # If just a base path to (e.g., a server directory) is passed, load all
         # .MER files contained there; otherwise read a single input file
-        if mmd_name is None:
-            mmd_files = glob.glob(os.path.join(base_path, "*.MER"))
+        if self.mer_name is None:
+            mer_files = glob.glob(os.path.join(self.base_path, "*.MER"))
         else:
-            mmd_files = glob.glob(os.path.join(base_path, mmd_name))
+            mer_files = glob.glob(os.path.join(self.base_path, self.mer_name))
 
-        for mmd_file in mmd_files:
-            mmd_data_name = mmd_file.split("/")[-1]
-            with open(mmd_file, "r") as f:
+        for mer_file in mer_files:
+            # This .MER file name
+            mer_binary_name = mer_file.split("/")[-1]
+
+            # The </EVENT> binary blocks contained in this .MER file
+            with open(mer_file, "r") as f:
                 content = f.read()
             events = content.split("</PARAMETERS>")[-1].split("<EVENT>")[1:]
+
             for event in events:
-                # Divide header and binary
-                header = event.split("<DATA>\x0A\x0D")[0]
-                binary = event.split("<DATA>\x0A\x0D")[1].split("\x0A\x0D\x09</DATA>")[0]
+                # The header of this specific </EVENT> block (NOT the </ENVIRONMENT> of
+                # the same .MER file, which may be unrelated (different time))
+                mer_binary_header = event.split("<DATA>\x0A\x0D")[0]
+
+                # The actual binary data contained in this </EVENT> block (the seismogram)
+                mer_binary_binary = event.split("<DATA>\x0A\x0D")[1].split("\x0A\x0D\x09</DATA>")[0]
 
                 # N.B:
                 # "\x0A" is "\n": True
@@ -69,13 +82,21 @@ class Events:
                 # returns the byte-length of a string, though I am not super
                 # happy with this solution because I would prefer to know the
                 # specific encoding used for event binary...)
-                actual_binary_length = len(binary)
-                bytes_per_sample = int(re.search('BYTES_PER_SAMPLE=(\d+)', header).group(1))
-                num_samples = int(re.search('LENGTH=(\d+)', header).group(1))
+                actual_binary_length = len(mer_binary_binary)
+                bytes_per_sample = int(re.search('BYTES_PER_SAMPLE=(\d+)', mer_binary_header).group(1))
+                num_samples = int(re.search('LENGTH=(\d+)', mer_binary_header).group(1))
                 expected_binary_length = bytes_per_sample * num_samples
 
                 if actual_binary_length == expected_binary_length:
-                    self.events.append(Event(mmd_data_name, header, binary))
+                    self.events.append(Event(mer_binary_name, mer_binary_header, mer_binary_binary))
+
+            # Sort by date the list of events contained in this .MER file
+            self.events.sort(key=lambda x: x.date)
+
+
+    def __repr__(self):
+        return "Events('{}', '{}')".format(self.base_path, self.mer_name)
+
 
     def get_events_between(self, begin, end):
         catched_events = list()
@@ -86,56 +107,77 @@ class Events:
 
 
 class Event:
-    mmd_data_name = None
-    mmd_file_is_complete = None
-    environment = None
-    header = None
-    binary = None
-    data = None
-    date = None
-    measured_fs = None   # Measured sampling frequency
-    decimated_fs = None  # Sampling frequency of the received data
-    trig = None
-    depth = None
-    temperature = None
-    criterion = None
-    snr = None
-    requested = None
-    station_loc = None
-    drift_correction = None
-    can_generate_mseed = False
-    can_generate_sac = False
-
-    def __init__(self, mmd_data_name, header, binary):
-        self.mmd_data_name = mmd_data_name
-        self.header = header
-        self.binary = binary
+    '''The Event (singular) class references TWO .MER files, which may be the same,
+    through Event.mer_binary_name (.MER file containing the </EVENT> binary
+    data), and Event.mer_environment_name (.MER file containing the
+    </ENVIRONMENT> metadata (e.g., GPS, clock drift, sampling freq. etc.)
+    associated with that event)
+
+    Only a SINGLE event (event binary block) is referenced by
+    Event.mer_binary_name and Event.mer_environment_name
+
+    '''
+
+    def __init__(self, mer_binary_name=None, mer_binary_header=None, mer_binary_binary=None):
+        self.mer_binary_name = mer_binary_name
+        self.mer_binary_header = mer_binary_header
+        self.mer_binary_binary = mer_binary_binary
         self.__version__ = version
 
-        self.scales = re.findall(" STAGES=(-?\d+)", self.header)[0]
-        catch_trig = re.findall(" TRIG=(\d+)", self.header)
+        # Defaults
+        self.mer_environment_name = None
+        self.mer_environment = None
+
+        self.data = None
+        self.measured_fs = None
+        self.decimated_fs = None
+        self.trig = None
+        self.depth = None
+        self.temperature = None
+        self.criterion = None
+        self.snr = None
+        self.scales = None
+
+        self.date = None
+        self.station_loc = None
+        self.clockdrift_correction = None
+
+        self.is_complete_mer_file = False
+        self.is_requested = False
+
+        self.scales = re.findall(" STAGES=(-?\d+)", self.mer_binary_header)[0]
+        catch_trig = re.findall(" TRIG=(\d+)", self.mer_binary_header)
         if len(catch_trig) > 0:
             # Event detected with STA/LTA algorithm
-            self.requested = False
             self.trig = int(catch_trig[0])
-            date = re.findall(" DATE=(\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d{6})", header, re.DOTALL)
+            date = re.findall(" DATE=(\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d{6})", mer_binary_header, re.DOTALL)
             self.date = UTCDateTime.strptime(date[0], "%Y-%m-%dT%H:%M:%S.%f")
-            self.depth = int(re.findall(" PRESSURE=(-?\d+)", self.header)[0])
-            self.temperature = int(re.findall(" TEMPERATURE=(-?\d+)", self.header)[0])
-            self.criterion = float(re.findall(" CRITERION=(\d+\.\d+)", self.header)[0])
-            self.snr = float(re.findall(" SNR=(\d+\.\d+)", self.header)[0])
+            self.depth = int(re.findall(" PRESSURE=(-?\d+)", self.mer_binary_header)[0])
+            self.temperature = int(re.findall(" TEMPERATURE=(-?\d+)", self.mer_binary_header)[0])
+            self.criterion = float(re.findall(" CRITERION=(\d+\.\d+)", self.mer_binary_header)[0])
+            self.snr = float(re.findall(" SNR=(\d+\.\d+)", self.mer_binary_header)[0])
         else:
             # Event requested by user
-            self.requested = True
-            date = re.findall(" DATE=(\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2})", header, re.DOTALL)
+            self.is_requested = True
+            date = re.findall(" DATE=(\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2})", mer_binary_header, re.DOTALL)
             self.date = UTCDateTime.strptime(date[0], "%Y-%m-%dT%H:%M:%S")
 
-    def set_environment(self, environment):
-        self.environment = environment
+    def __repr__(self):
+        # Hacked repr dunder because I can't print binary...
+        if self.mer_binary_binary:
+            bin_str = '<int32 binary>'
+        else:
+            bin_str = self.mer_binary_binary
+
+        return "Event('{}', '{}', {})".format(self.mer_binary_name, self.mer_binary_header, bin_str)
+
+    def set_environment(self, mer_environment_name, mer_environment):
+        self.mer_environment_name = mer_environment_name
+        self.mer_environment = mer_environment
 
     def find_measured_sampling_frequency(self):
         # Get the frequency recorded in the .MER environment header
-        fs_catch = re.findall("TRUE_SAMPLE_FREQ FS_Hz=(\d+\.\d+)", self.environment)
+        fs_catch = re.findall("TRUE_SAMPLE_FREQ FS_Hz=(\d+\.\d+)", self.mer_environment)
         self.measured_fs = float(fs_catch[0])
         #self.measured_fs = 40
 
@@ -149,16 +191,16 @@ class Event:
 
     def correct_date(self):
         # Calculate the date of the first sample
-        if self.requested:
+        if self.is_requested:
             # For a requested event
-            rec_file_date = re.findall("FNAME=(\d{4}-\d{2}-\d{2}T\d{2}_\d{2}_\d{2})", self.header)
+            rec_file_date = re.findall("FNAME=(\d{4}-\d{2}-\d{2}T\d{2}_\d{2}_\d{2})", self.mer_binary_header)
             rec_file_date = UTCDateTime.strptime(rec_file_date[0], "%Y-%m-%dT%H_%M_%S")
 
-            rec_file_ms = re.findall("FNAME=\d{4}-\d{2}-\d{2}T\d{2}_\d{2}_\d{2}\.?(\d{6}?)", self.header)
+            rec_file_ms = re.findall("FNAME=\d{4}-\d{2}-\d{2}T\d{2}_\d{2}_\d{2}\.?(\d{6}?)", self.mer_binary_header)
             if len(rec_file_ms) > 0:
                 rec_file_date += float("0." + rec_file_ms[0])
 
-            sample_offset = re.findall("SMP_OFFSET=(\d+)", self.header)
+            sample_offset = re.findall("SMP_OFFSET=(\d+)", self.mer_binary_header)
             sample_offset = float(sample_offset[0])
             self.date = rec_file_date + sample_offset/self.measured_fs
         else:
@@ -166,25 +208,29 @@ class Event:
             # The recorded date is the STA/LTA trigger date, subtract the time before the trigger.
             self.date = self.date - float(self.trig) / self.decimated_fs
 
-    def correct_clock_drift(self, gps_descent, gps_ascent):
+    def correct_clockdrift(self, gps_descent, gps_ascent):
         # Correct the clock drift of the Mermaid board with GPS measurement
         pct = (self.date - gps_descent.date) / (gps_ascent.date - gps_descent.date)
-        self.drift_correction = gps_ascent.clockdrift * pct
+        self.clockdrift_correction = gps_ascent.clockdrift * pct
         # Apply correction
-        self.date = self.date + self.drift_correction
+        self.date = self.date + self.clockdrift_correction
 
     def compute_station_location(self, drift_begin_gps, drift_end_gps):
+        '''Fills attribute self.station_loc, the interpolated location of MERMAID when
+        it recorded an event
+
+        '''
         self.station_loc = gps.linear_interpolation([drift_begin_gps, drift_end_gps], self.date)
 
     def invert_transform(self, bin_path=os.path.join(os.environ["AUTOMAID"], "scripts", "bin")):
         # If scales == -1 this is a raw signal, just convert binary data to numpy array of int32
         if self.scales == "-1":
-            self.data = numpy.frombuffer(self.binary, numpy.int32)
+            self.data = numpy.frombuffer(self.mer_binary_binary, numpy.int32)
             return
 
         # Get additional information on flavor of invert wavelet transform
-        normalized = re.findall(" NORMALIZED=(\d+)", self.environment)[0]
-        edge_correction = re.findall(" EDGES_CORRECTION=(\d+)", self.environment)[0]
+        normalized = re.findall(" NORMALIZED=(\d+)", self.mer_environment)[0]
+        edge_correction = re.findall(" EDGES_CORRECTION=(\d+)", self.mer_environment)[0]
 
         # Change to binary directory because these scripts can fail with full paths
         start_dir = os.getcwd();
@@ -207,7 +253,7 @@ class Event:
 
         # Write cdf24 data
         with open(wtcoeffs_data_file_name, 'w') as f:
-            f.write(self.binary)
+            f.write(self.mer_binary_binary)
 
         # The inverse wavelet transform C code (icdf24_v103(ec)_test) is called
         # below in a subprocess and its output is verified; determine if edge
@@ -233,7 +279,7 @@ class Event:
             err_mess = "\nFailed: inverse wavelet transformation\n"
             err_mess += "In directory: {:s}\n".format(bin_path)
             err_mess += "Attempted command: {:s}\n".format(cmd)
-            err_mess += "Using: event around {:s} in {:s}\n\n".format(self.date, self.mmd_data_name)
+            err_mess += "Using: event around {:s} in {:s}\n\n".format(self.date, self.mer_binary_name)
             err_mess += "Command printout:\n'{:s}'".format(stdout)
 
             # This output message is more helpful than the program crashing on
@@ -253,7 +299,7 @@ class Event:
         os.chdir(start_dir)
 
     def get_export_file_name(self):
-        export_file_name = UTCDateTime.strftime(UTCDateTime(self.date), "%Y%m%dT%H%M%S") + "." + self.mmd_data_name
+        export_file_name = UTCDateTime.strftime(UTCDateTime(self.date), "%Y%m%dT%H%M%S") + "." + self.mer_binary_name
         if not self.trig:
             export_file_name = export_file_name + ".REQ"
         else:
@@ -273,10 +319,10 @@ class Event:
                 + "     SNR = " + str(self.snr)
         return title
 
-    def plotly(self, export_path):
+    def plotly(self, export_path, force_redo=False):
         # Check if file exist
-        export_path = export_path + self.get_export_file_name() + ".html"
-        if os.path.exists(export_path):
+        export_path_html = export_path + self.get_export_file_name() + ".html"
+        if not force_redo and os.path.exists(export_path_html):
             return
 
         # Add acoustic values to the graph
@@ -296,14 +342,15 @@ class Event:
                               )
 
         plotly.plot({'data': data, 'layout': layout},
-                    filename=export_path,
+                    filename=export_path_html,
                     auto_open=False)
 
-    def plot_png(self, export_path):
+    def plot_png(self, export_path, force_redo=False):
         # Check if file exist
-        export_path = export_path + self.get_export_file_name() + ".png"
-        if os.path.exists(export_path):
+        export_path_png = export_path + self.get_export_file_name() + ".png"
+        if not force_redo and os.path.exists(export_path_png):
             return
+
         data = [d/(10**((-201.+25.)/20.) * 2 * 2**28/5. * 1000000) for d in self.data]
 
         # Plot frequency image
@@ -316,22 +363,19 @@ class Event:
         plt.ylabel("Pascal", fontsize=12)
         plt.tight_layout()
         plt.grid()
-        plt.savefig(export_path)
+        plt.savefig(export_path_png)
         plt.clf()
         plt.close()
 
-    def to_mseed(self, export_path, station_number, force_without_loc=False):
+    def to_mseed(self, export_path, station_number, force_without_loc=False, force_redo=False):
         # Check if the station location has been calculated
         if self.station_loc is None and not force_without_loc:
             #print self.get_export_file_name() + ": Skip mseed generation, wait the next ascent to compute location"
             return
 
-        # This binary data attached to this event may be converted to miniSEED
-        self.can_generate_mseed = True
-
         # Check if file exist
         export_path_msd = export_path + self.get_export_file_name() + ".mseed"
-        if os.path.exists(export_path_msd):
+        if not force_redo and os.path.exists(export_path_msd):
             return
 
         # Get stream object
@@ -340,18 +384,15 @@ class Event:
         # Save stream object
         stream.write(export_path_msd, format='MSEED')
 
-    def to_sac(self, export_path, station_number, force_without_loc=False):
+    def to_sac(self, export_path, station_number, force_without_loc=False, force_redo=False):
         # Check if the station location has been calculated
         if self.station_loc is None and not force_without_loc:
-            print self.get_export_file_name() + ": Skip sac generation, wait the next ascent to compute location"
+            #print self.get_export_file_name() + ": Skip sac generation, wait the next ascent to compute location"
             return
 
-        # This binary data attached to this event may be converted to SAC
-        self.can_generate_sac = True
-
         # Check if file exist
         export_path_sac = export_path + self.get_export_file_name() + ".sac"
-        if os.path.exists(export_path_sac):
+        if not force_redo and os.path.exists(export_path_sac):
             return
 
         # Get stream object
@@ -361,18 +402,11 @@ class Event:
         stream.write(export_path_sac, format='SAC')
 
     def get_stream(self, export_path, station_number, force_without_loc=False):
-        # Check if file exist
-        export_path_sac = export_path + self.get_export_file_name() + ".sac"
-        export_path_msd = export_path + self.get_export_file_name() + ".mseed"
-        if os.path.exists(export_path_sac) and os.path.exists(export_path_msd):
-            return
-
-        # Check if the station location have been calculated
+       # Check if an interpolated station location exists
         if self.station_loc is None and not force_without_loc:
-            print self.get_export_file_name() + ": Skip sac/mseed generation, wait the next ascent to compute location"
             return
 
-        # Fill header info
+        # Fill SAC header info
         stats = Stats()
         stats.sampling_rate = self.decimated_fs
         stats.network = "MH"
@@ -386,10 +420,7 @@ class Event:
         stats.sac["user0"] = self.snr
         stats.sac["user1"] = self.criterion
         stats.sac["user2"] = self.trig # samples
-        if self.drift_correction is not None:
-            stats.sac["user3"] = self.drift_correction # seconds
-        else:
-            stats.sac["user3"] = -12345.0 # undefined default
+        stats.sac["user3"] = self.clockdrift_correction # seconds
         stats.sac["kuser0"] = self.__version__
         stats.sac["iztype"] = 9  # 9 == IB in sac format
 
@@ -400,3 +431,18 @@ class Event:
         stream = Stream(traces=[trace])
 
         return stream
+
+
+def write_traces_txt(mdives, processed_path, mfloat_path, mfloat):
+    fmt_spec = '{:>40s}    {:>15s}    {:>15s}    {:>15s}    {:>15s}    {:>15s}\n'
+    traces_file = os.path.join(processed_path, mfloat_path, mfloat+"_traces.txt")
+    event_dive_tup = ((event, dive) for dive in mdives for event in dive.events if event.station_loc)
+    with open(traces_file, "w+") as f:
+        f.write("            	         SAC_MSEED_TRACE            BIN_MER      THIS_DIVE_LOG  THIS_DIVE_ENV_MER      NEXT_DIVE_LOG  NEXT_DIVE_ENV_MER\n".format())
+        for e, d in sorted(event_dive_tup, key=lambda x: x[0].date):
+            f.write(fmt_spec.format(e.get_export_file_name(),
+                                    e.mer_binary_name,
+                                    d.log_name,
+                                    d.mer_environment_name,
+                                    d.next_dive_log_name,
+                                    d.next_dive_mer_environment_name))
